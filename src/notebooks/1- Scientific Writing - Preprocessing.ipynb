{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/iphra/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import nltk\n",
    "import collections\n",
    "import itertools\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[\"didn't\",\n \"mightn't\",\n \"wasn't\",\n \"shouldn't\",\n \"doesn't\",\n \"mustn't\",\n \"shan't\",\n \"isn't\",\n \"hadn't\",\n \"won't\",\n \"haven't\",\n \"needn't\",\n \"hasn't\",\n \"couldn't\",\n \"don't\",\n \"aren't\",\n \"weren't\",\n \"wouldn't\"]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "stop_words = [str(w) for w in stop_words]\n",
    "negative_stop_words = [w for w in stop_words if \"'t\" in w]\n",
    "negative_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem: contain negative words\n",
    "- As we can see, there are many negative words. \n",
    "- We would like to inglobe them all in a label \"not\" or negative_word label\n",
    "\n",
    "Firstly, we will remove those negative words from the stopwords, then we will transform all those words in the negative tag (similarly to what happens for the laugh_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Remove negative words\n",
    "stop_words_avoidnot = [w for w in stop_words if \"'t\" not in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Put negative_word label\n",
    "negative_stop_words = [w for w in stop_words if \"'t\" in w]\n",
    "negative_stop_words += [\"dont\", \"cant\", \"dnt\"] #TODO: maybe search for others?\n",
    "text = [\"prova\", \"doesn't\"]\n",
    "text_new = []\n",
    "for w in text:\n",
    "    if w not in negative_stop_words:\n",
    "        text_new += [w]\n",
    "    else:\n",
    "        text_new += \"negative_word\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove singleton from the tweets\n",
    "- 1- get frequencies of each word \n",
    "- 2- find the singleton and save in list\n",
    "\n",
    "We will remove the singleton from the tweets in every iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# tweets_nsw is the list of lists containing the tweets\n",
    "# Since I have a dataframe, I read a column as list of lists\n",
    "\n",
    "tweets_nsw = [[\"Ciao\", \"come\", \"va\"], [\"Ciao\", \"va\"]]\n",
    "all_words_nsw = list(itertools.chain(*tweets_nsw))\n",
    "\n",
    "counts_nsw = collections.Counter(all_words_nsw) # Is a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "singletons = []\n",
    "for k in counts_nsw.keys():\n",
    "    if counts_nsw.get(k) == 1:\n",
    "        singletons += [k]\n",
    "        \n",
    "        \n",
    "# FInally add to the list of words to be removed\n",
    "words_to_remove = []\n",
    "words_to_remove += stop_words\n",
    "words_to_remove += singletons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['come']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 9
    }
   ],
   "source": [
    "singletons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}